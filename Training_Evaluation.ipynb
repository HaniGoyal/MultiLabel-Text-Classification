{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8116555,"sourceType":"datasetVersion","datasetId":4795424}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-15T13:59:59.709711Z","iopub.execute_input":"2024-04-15T13:59:59.710099Z","iopub.status.idle":"2024-04-15T14:00:00.064845Z","shell.execute_reply.started":"2024-04-15T13:59:59.710066Z","shell.execute_reply":"2024-04-15T14:00:00.063918Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/Multi-Label Text Classification Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import metrics\nimport transformers\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, BertModel\nimport re\nimport tqdm.notebook as tq","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:00.066758Z","iopub.execute_input":"2024-04-15T14:00:00.067122Z","iopub.status.idle":"2024-04-15T14:00:04.144742Z","shell.execute_reply.started":"2024-04-15T14:00:00.067098Z","shell.execute_reply":"2024-04-15T14:00:04.143960Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# DATA LOADING AND PREPROCESSING","metadata":{}},{"cell_type":"code","source":"data = '/kaggle/input/dataset/Multi-Label Text Classification Dataset.csv'\ndf = pd.read_csv(data)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:04.145834Z","iopub.execute_input":"2024-04-15T14:00:04.146314Z","iopub.status.idle":"2024-04-15T14:00:05.695954Z","shell.execute_reply.started":"2024-04-15T14:00:04.146285Z","shell.execute_reply":"2024-04-15T14:00:05.694961Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                               Title  \\\n0  Expression of p53 and coexistence of HPV in pr...   \n1  Vitamin D status in pregnant Indian women acro...   \n2  [Identification of a functionally important di...   \n3  Multilayer capsules: a promising microencapsul...   \n4  Nanohydrogel with N,N'-bis(acryloyl)cystine cr...   \n\n                                        abstractText  \\\n0  Fifty-four paraffin embedded tissue sections f...   \n1  The present cross-sectional study was conducte...   \n2  The occurrence of individual amino acids and d...   \n3  In 1980, Lim and Sun introduced a microcapsule...   \n4  Substantially improved hydrogel particles base...   \n\n                                           meshMajor      pmid  \\\n0  ['DNA Probes, HPV', 'DNA, Viral', 'Female', 'H...   8549602   \n1  ['Adult', 'Alkaline Phosphatase', 'Breast Feed...  21736816   \n2  ['Amino Acid Sequence', 'Analgesics, Opioid', ...  19060934   \n3  ['Acrylic Resins', 'Alginates', 'Animals', 'Bi...  11426874   \n4  ['Antineoplastic Agents', 'Cell Proliferation'...  28323099   \n\n                                              meshid  \\\n0  [['D13.444.600.223.555', 'D27.505.259.750.600....   \n1  [['M01.060.116'], ['D08.811.277.352.650.035'],...   \n2  [['G02.111.570.060', 'L01.453.245.667.060'], [...   \n3  [['D05.750.716.822.111', 'D25.720.716.822.111'...   \n4  [['D27.505.954.248'], ['G04.161.750', 'G07.345...   \n\n                                            meshroot  A  B  C  D  E  F  G  H  \\\n0  ['Chemicals and Drugs [D]', 'Organisms [B]', '...  0  1  1  1  1  0  0  1   \n1  ['Named Groups [M]', 'Chemicals and Drugs [D]'...  0  1  1  1  1  1  1  0   \n2  ['Phenomena and Processes [G]', 'Information S...  1  1  0  1  1  0  1  0   \n3  ['Chemicals and Drugs [D]', 'Technology, Indus...  1  1  1  1  1  0  1  0   \n4  ['Chemicals and Drugs [D]', 'Phenomena and Pro...  1  1  0  1  1  0  1  0   \n\n   I  J  L  M  N  Z  \n0  0  0  0  0  0  0  \n1  1  1  0  1  1  1  \n2  0  0  1  0  0  0  \n3  0  1  0  0  0  0  \n4  0  1  0  0  0  0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>abstractText</th>\n      <th>meshMajor</th>\n      <th>pmid</th>\n      <th>meshid</th>\n      <th>meshroot</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>F</th>\n      <th>G</th>\n      <th>H</th>\n      <th>I</th>\n      <th>J</th>\n      <th>L</th>\n      <th>M</th>\n      <th>N</th>\n      <th>Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Expression of p53 and coexistence of HPV in pr...</td>\n      <td>Fifty-four paraffin embedded tissue sections f...</td>\n      <td>['DNA Probes, HPV', 'DNA, Viral', 'Female', 'H...</td>\n      <td>8549602</td>\n      <td>[['D13.444.600.223.555', 'D27.505.259.750.600....</td>\n      <td>['Chemicals and Drugs [D]', 'Organisms [B]', '...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Vitamin D status in pregnant Indian women acro...</td>\n      <td>The present cross-sectional study was conducte...</td>\n      <td>['Adult', 'Alkaline Phosphatase', 'Breast Feed...</td>\n      <td>21736816</td>\n      <td>[['M01.060.116'], ['D08.811.277.352.650.035'],...</td>\n      <td>['Named Groups [M]', 'Chemicals and Drugs [D]'...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Identification of a functionally important di...</td>\n      <td>The occurrence of individual amino acids and d...</td>\n      <td>['Amino Acid Sequence', 'Analgesics, Opioid', ...</td>\n      <td>19060934</td>\n      <td>[['G02.111.570.060', 'L01.453.245.667.060'], [...</td>\n      <td>['Phenomena and Processes [G]', 'Information S...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Multilayer capsules: a promising microencapsul...</td>\n      <td>In 1980, Lim and Sun introduced a microcapsule...</td>\n      <td>['Acrylic Resins', 'Alginates', 'Animals', 'Bi...</td>\n      <td>11426874</td>\n      <td>[['D05.750.716.822.111', 'D25.720.716.822.111'...</td>\n      <td>['Chemicals and Drugs [D]', 'Technology, Indus...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nanohydrogel with N,N'-bis(acryloyl)cystine cr...</td>\n      <td>Substantially improved hydrogel particles base...</td>\n      <td>['Antineoplastic Agents', 'Cell Proliferation'...</td>\n      <td>28323099</td>\n      <td>[['D27.505.954.248'], ['G04.161.750', 'G07.345...</td>\n      <td>['Chemicals and Drugs [D]', 'Phenomena and Pro...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf['labels'] = df[df.columns[6:]].values.tolist()\nselected_columns = ['Title', 'abstractText', 'meshMajor', 'labels']\ndf = df[selected_columns]\n\n#Training (70%), Testing (15%), Validation (15%)\ntrain_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\ntest_data, val_data = train_test_split(test_data, test_size=0.5, random_state=42)\n\ntrain_data = train_data.reset_index(drop = True)\ntest_data = test_data.reset_index(drop = True)\nval_data = val_data.reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:05.697533Z","iopub.execute_input":"2024-04-15T14:00:05.697898Z","iopub.status.idle":"2024-04-15T14:00:05.941757Z","shell.execute_reply.started":"2024-04-15T14:00:05.697866Z","shell.execute_reply":"2024-04-15T14:00:05.940960Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 16\nTEST_BATCH_SIZE = 8\nEPOCHS = 3\nLEARNING_RATE = 1e-05\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:05.944122Z","iopub.execute_input":"2024-04-15T14:00:05.944437Z","iopub.status.idle":"2024-04-15T14:00:06.243784Z","shell.execute_reply.started":"2024-04-15T14:00:05.944412Z","shell.execute_reply":"2024-04-15T14:00:06.242794Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class myDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, maxlen):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.targets = dataframe.labels\n        self.max_len = maxlen\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        wordList = []\n        wordList.append('Title:')\n        title_text = str(self.data.Title[index])\n        wordList.extend(title_text.split())\n        wordList.append('Abstract:')\n        abstract_text = str(self.data.abstractText[index])\n        wordList.extend(abstract_text.split())\n        wordList.append('Terms:')\n        mesh_text = str(self.data.meshMajor[index])\n        wordList.extend(re.findall(r\"'(.*?)'\", mesh_text))\n        \n        x = \" \".join(wordList)\n        \n        inputs = self.tokenizer.encode_plus(\n            x,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            truncation = True,\n            padding = \"max_length\",\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n            'combinedText': x\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:06.244924Z","iopub.execute_input":"2024-04-15T14:00:06.245205Z","iopub.status.idle":"2024-04-15T14:00:06.255460Z","shell.execute_reply.started":"2024-04-15T14:00:06.245181Z","shell.execute_reply":"2024-04-15T14:00:06.254540Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset = myDataset(train_data, tokenizer, MAX_LEN)\ntest_dataset = myDataset(test_data, tokenizer, MAX_LEN)\nval_dataset = myDataset(val_data, tokenizer, MAX_LEN)\n \ntrain_data_loader = torch.utils.data.DataLoader(train_dataset, \n    batch_size=TRAIN_BATCH_SIZE,\n    shuffle=True,\n    num_workers=0\n)\n\nval_data_loader = torch.utils.data.DataLoader(val_dataset, \n    batch_size=VALID_BATCH_SIZE,\n    shuffle=False,\n    num_workers=0\n)\n\ntest_data_loader = torch.utils.data.DataLoader(test_dataset, \n    batch_size=TEST_BATCH_SIZE,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:06.256507Z","iopub.execute_input":"2024-04-15T14:00:06.256836Z","iopub.status.idle":"2024-04-15T14:00:06.270280Z","shell.execute_reply.started":"2024-04-15T14:00:06.256811Z","shell.execute_reply":"2024-04-15T14:00:06.269443Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# MODEL ARCHITECTURE","metadata":{}},{"cell_type":"code","source":"class modelArchitecture(nn.Module):\n    def __init__(self):\n        super(modelArchitecture, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased', return_dict = True)\n        self.dropout = nn.Dropout(0.3)\n        self.layer = nn.Linear(768, 14)\n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.bert(\n            input_ids, \n            attention_mask=attn_mask, \n            token_type_ids=token_type_ids\n        )\n        output = self.dropout(output.pooler_output)\n        output = self.layer(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:06.271241Z","iopub.execute_input":"2024-04-15T14:00:06.271503Z","iopub.status.idle":"2024-04-15T14:00:06.284218Z","shell.execute_reply.started":"2024-04-15T14:00:06.271463Z","shell.execute_reply":"2024-04-15T14:00:06.283500Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = modelArchitecture()\n\n#for param in model.bert.parameters():\n#    param.requires_grad = False\n    \ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:06.285201Z","iopub.execute_input":"2024-04-15T14:00:06.285446Z","iopub.status.idle":"2024-04-15T14:00:07.599388Z","shell.execute_reply.started":"2024-04-15T14:00:06.285426Z","shell.execute_reply":"2024-04-15T14:00:07.598441Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"modelArchitecture(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (layer): Linear(in_features=768, out_features=14, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:07.600546Z","iopub.execute_input":"2024-04-15T14:00:07.600832Z","iopub.status.idle":"2024-04-15T14:00:07.606753Z","shell.execute_reply.started":"2024-04-15T14:00:07.600808Z","shell.execute_reply":"2024-04-15T14:00:07.605793Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# MODEL TRAINING","metadata":{}},{"cell_type":"code","source":"def trainModel(train_dataloader, model, optimizer, criterion):\n    losses = []\n    model.train()\n    loop = tq.tqdm(enumerate(train_dataloader), total=len(train_dataloader), \n                      leave=True, colour='steelblue')\n    for batch_idx, data in loop:\n        ids = data['ids'].to(device, dtype = torch.long)\n        attn_mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n        \n        #forward\n        outputs = model(ids, attn_mask, token_type_ids)\n        loss = criterion(outputs, targets)\n        losses.append(loss.item())\n        #print(loss.item())\n        #backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    return model, losses\n\ndef evalModel(val_dataloader, model, optimizer, criterion):\n    losses = []\n    model.eval()\n    \n    with torch.no_grad():\n        for batch_idx, data in enumerate(val_dataloader):\n            ids = data['ids'].to(device, dtype = torch.long)\n            attn_mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            \n            outputs = model(ids, attn_mask, token_type_ids)\n            loss = criterion(outputs, targets)\n            losses.append(loss.item())\n            \n    return losses","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:07.607955Z","iopub.execute_input":"2024-04-15T14:00:07.608249Z","iopub.status.idle":"2024-04-15T14:00:07.620458Z","shell.execute_reply.started":"2024-04-15T14:00:07.608216Z","shell.execute_reply":"2024-04-15T14:00:07.619689Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"bestLoss = 1\nmodel_save_path = '/kaggle/working/model.pth'\nfor epoch in range(EPOCHS):\n    print(f'Epoch: {epoch}')\n    model, train_losses = trainModel(train_data_loader, model, optimizer, criterion)\n    val_losses = evalModel(val_data_loader, model, optimizer, criterion)\n    train_loss = np.mean(train_losses)\n    val_loss = np.mean(val_losses)\n    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f}')\n    \n    if train_loss < bestLoss:\n        torch.save(model.state_dict(), model_save_path)\n        bestLoss = train_loss","metadata":{"execution":{"iopub.status.busy":"2024-04-15T14:00:07.621470Z","iopub.execute_input":"2024-04-15T14:00:07.621735Z","iopub.status.idle":"2024-04-15T15:42:42.725724Z","shell.execute_reply.started":"2024-04-15T14:00:07.621713Z","shell.execute_reply":"2024-04-15T15:42:42.724498Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed1711425ba340279dbce929c7ecee58"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.2848, val_loss=0.1750\nEpoch: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09a040337f424392a26a152d263ef48b"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.1445, val_loss=0.1156\nEpoch: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2188 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e2874c12e645da9589449b03937d86"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.1001, val_loss=0.0959\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# MODEL EVALUATION","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = modelArchitecture()\nmodel.load_state_dict(torch.load(model_save_path))\nmodel = model.to(device)\n\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:47:46.237015Z","iopub.execute_input":"2024-04-15T15:47:46.237951Z","iopub.status.idle":"2024-04-15T15:47:47.686876Z","shell.execute_reply.started":"2024-04-15T15:47:46.237916Z","shell.execute_reply":"2024-04-15T15:47:47.685916Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"modelArchitecture(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (layer): Linear(in_features=768, out_features=14, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"test_losses = evalModel(test_data_loader, model, optimizer, criterion)\nprint(np.mean(test_losses))","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:49:11.110299Z","iopub.execute_input":"2024-04-15T15:49:11.111453Z","iopub.status.idle":"2024-04-15T15:52:40.017389Z","shell.execute_reply.started":"2024-04-15T15:49:11.111404Z","shell.execute_reply":"2024-04-15T15:52:40.016468Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"0.09406954222031112\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ndef get_predictions(model, data_loader):\n    \"\"\"\n    Outputs:\n      predictions - \n    \"\"\"\n    model = model.eval()\n    \n    predictions = []\n    prediction_probs = []\n    target_values = []\n\n    with torch.no_grad():\n      for data in data_loader:\n        ids = data[\"ids\"].to(device, dtype = torch.long)\n        mask = data[\"mask\"].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data[\"targets\"].to(device, dtype = torch.float)\n        \n        outputs = model(ids, mask, token_type_ids)\n        # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n        outputs = torch.sigmoid(outputs).detach().cpu()\n        # thresholding at 0.5\n        preds = outputs.round()\n        targets = targets.detach().cpu()\n\n        predictions.extend(preds)\n        prediction_probs.extend(outputs)\n        target_values.extend(targets)\n    \n    predictions = torch.stack(predictions)\n    prediction_probs = torch.stack(prediction_probs)\n    target_values = torch.stack(target_values)\n    \n    return predictions, prediction_probs, target_values","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:00:13.067095Z","iopub.execute_input":"2024-04-15T16:00:13.068057Z","iopub.status.idle":"2024-04-15T16:00:13.077231Z","shell.execute_reply.started":"2024-04-15T16:00:13.068025Z","shell.execute_reply":"2024-04-15T16:00:13.076155Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"predictions, prediction_probs, target_values = get_predictions(model, test_data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:00:13.961088Z","iopub.execute_input":"2024-04-15T16:00:13.961958Z","iopub.status.idle":"2024-04-15T16:03:41.226831Z","shell.execute_reply.started":"2024-04-15T16:00:13.961926Z","shell.execute_reply":"2024-04-15T16:03:41.225954Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"target_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'Z']\nprint(classification_report(target_values, predictions, target_names=target_list))","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:10:33.600708Z","iopub.execute_input":"2024-04-15T16:10:33.601148Z","iopub.status.idle":"2024-04-15T16:10:33.637340Z","shell.execute_reply.started":"2024-04-15T16:10:33.601098Z","shell.execute_reply":"2024-04-15T16:10:33.636513Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           A       0.97      0.95      0.96      3488\n           B       0.99      1.00      0.99      6957\n           C       0.97      0.97      0.97      3910\n           D       0.98      0.99      0.98      4651\n           E       0.96      0.97      0.97      5909\n           F       0.94      0.93      0.94      1337\n           G       0.96      0.96      0.96      5059\n           H       0.94      0.87      0.91       967\n           I       0.92      0.84      0.88       873\n           J       0.96      0.78      0.86       873\n           L       0.94      0.94      0.94      1161\n           M       0.98      0.99      0.99      3131\n           N       0.93      0.96      0.95      3396\n           Z       0.98      0.96      0.97      1221\n\n   micro avg       0.97      0.96      0.96     42933\n   macro avg       0.96      0.94      0.95     42933\nweighted avg       0.97      0.96      0.96     42933\n samples avg       0.97      0.96      0.96     42933\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}